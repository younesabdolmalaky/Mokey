# Mokey Species classification
![primate_collage](https://user-images.githubusercontent.com/75095471/218704518-b58d496a-19a1-4d4d-8a2e-b49b71de7ac3.jpg)
## Species classification using color and texture features
<b>Reading images:</b> The code reads images from the given directories and converts them to grayscale. It also extracts the hue and Haralick texture features from each image using OpenCV and Mahotas libraries.

<b>Calculating histograms:</b> The code calculates color histograms for each image using the OpenCV library.

<b>Concatenating features:</b> The code concatenates the color histograms with the extracted hue and Haralick texture features.

<b>Handling data:</b> The code processes the concatenated features and their labels.

<b>Applying classifiers: </b>The script applies two classifiers, CatBoost and Random Forest, to predict the labels of test images using the processed training data.

<b>Evaluating the classifiers: </b>The code prints the classification report for each classifier.

The input to the code is the name of the directory containing the training images. The output is the classification report for each classifier.

## Species Classification with Convolutional Neural Network (CNN) using Keras and TensorFlow

Code Overview
The code starts by importing the necessary libraries, including NumPy, Pandas, Matplotlib, and Keras/TensorFlow. It then defines the architecture of the CNN model using the Sequential API, which includes several convolutional layers, pooling layers, and fully connected layers.

Next, an ImageDataGenerator is defined for both the training and testing data. The training data is generated by applying various transformations to the images such as rescaling, zooming, and shifting, and the testing data is only rescaled.

The flow_from_directory() method is used to load the training data from a directory of images, and it automatically labels the images based on the subdirectories they are located in.

The model is compiled with an Adam optimizer, categorical cross-entropy loss function, and accuracy as the metric to optimize. The fit() method is then used to train the model on the training data for 50 epochs, and the training accuracy and loss are stored in the history variable.

In conclusion, this code provides an example of how to build and train an image classification model using a convolutional neural network in Keras with TensorFlow. It demonstrates the importance of data augmentation to improve the model's accuracy and how to monitor the training progress using the fit() method.


## Transfer Learning with VGG16 and VGG19 for Species Classification

the code uses transfer learning with the pre-trained VGG16 and VGG19 model for image classification on a custom dataset. The VGG16 and VGG19 model is loaded with pre-trained weights on the ImageNet dataset and its top layer is removed to be replaced with custom layers for our specific classification task.

The custom model consists of a Flatten layer, followed by a Dense layer with 256 units and ReLU activation function, a Dropout layer with a rate of 0.5 to prevent overfitting, and finally a Dense layer with 10 units and Softmax activation function for multi-class classification. The model is then compiled with the Adam optimizer, categorical cross-entropy loss, and accuracy metrics.

Two ImageDataGenerators are used for data augmentation on the training and validation datasets. These generators perform image rescaling and apply various transformation techniques, including zooming and shifting, to increase the size and diversity of the training set.
The model is trained using the fit_generator method, which takes the training and validation data generators as inputs and trains the VGG16 model for 30 epochs and VGG19 for 200. At each epoch, the validation data is also evaluated, and the metrics are printed out. Finally, the classification report from scikit-learn is imported to evaluate the model's performance.

<table>
  <tr>
    <th>Model</th>
    <th>Accuracy (%)</th>
  </tr>
  <tr>
    <td>Classic Machine Learning</td>
    <td>51</td>
  </tr>
  <tr>
    <td>CNN</td>
    <td>62</td>
  </tr>
  <tr>
    <td>VGG16</td>
    <td>72</td>
  </tr>
   <tr>
    <td>VGG19</td>
    <td>92</td>
  </tr>
</table>

![download (8)](https://user-images.githubusercontent.com/75095471/218705175-cef6958c-e34f-4c29-b854-d3f13420c41d.png)
